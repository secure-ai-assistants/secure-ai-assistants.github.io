---
layout: page
#
# Content
#
subheadline: "Always Listening Podcast"
title: "Episode 2: My data and controlling how it is used"
teaser: "In today's connected world it is common to be asked for your data, and users may consent without any understanding of how their information is being used. Although this is often standard practice, knowledge about how your data is being used should be made available through privacy policies, as it is a legal requirement."
categories:
  - outreach
tags:
  - outreach
#
# Styling
#
header: no
image:
    title: podcast-logo-2.png
    thumb: podcast-logo-2.png
    homepage: podcast-logo-2.png
    caption: Always Listening Podcast
    caption_url: https://redcircle.com/shows/682c5268-774d-4595-bb44-c799f451cf8c
mediaplayer: false
author: wseymour
---

However, all too often privacy policies are overlooked, inadequate or simply not made available by the service provider. How often do data privacy inconsistencies occur in voice AI Assistants? This is the ‘black box’ challenge that the SAIS research team have put their minds to - and the result was the Skillvet project.

In this episode we take a fresh look at privacy in the AI Assistant ecosystem. We discuss how recent privacy rules like GDPR are affecting businesses and users, and consider what more can be done to protect users. And we will find out about the key challenges for users in understanding and controlling how their data is used. 

As well as this research, in this episode we discuss:
* What data does the AI Assistant hold about you?
* How can you control use of your data by skills and the AI assistant ecosystem?
* How transparent are skills about how they use data? And how does the Skillvet tool help us assess this?

Find out more about Skillvet in our blog post about [Improving transparency in AI Assistants](https://secure-ai-assistants.github.io/outreach/blog2/).

<script async defer onload="redcircleIframe();" src="https://api.podcache.net/embedded-player/sh/682c5268-774d-4595-bb44-c799f451cf8c/ep/2f913042-bebc-4d00-98c3-1934e712b07c"></script>
<div class="redcirclePlayer-2f913042-bebc-4d00-98c3-1934e712b07c"></div>
<style>
.redcircle-link:link {
    color: #ea404d;
    text-decoration: none;
}
.redcircle-link:hover {
    color: #ea404d;
}
.redcircle-link:active {
    color: #ea404d;
}
.redcircle-link:visited {
    color: #ea404d;
}
</style>
<p style="margin-top:3px;margin-left:11px;font-family: sans-serif;font-size: 10px; color: gray;">Powered by <a class="redcircle-link" href="https://redcircle.com?utm_source=rc_embedded_player&utm_medium=web&utm_campaign=embedded_v1">RedCircle</a></p>

We would love to hear your thoughts and comments on this podcast episode! <br />
Tweet us [@SecureAI_SAIS](https://twitter.com/SecureAI_SAIS) <br />
Connect with us on LinkedIn [SAIS project](https://www.linkedin.com/company/sais-project) <br />
Contact the show producers, Helix Data Innovation, on sais-comms@kcl.ac.uk

