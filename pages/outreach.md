---
layout: page
show_meta: false
title: "Our engagement activities to share our research"
subheadline: "Outreach"
header:
   image_fullwidth: "header-ghome.jpg"
permalink: "/outreach/"
---

{% assign url = site.baseurl | prepend: site.url %}

__Part of our mission is to share insights from our work through engagement and outreach activities.__

### Research Blog 
In our research blogs series we tell the story of our research, present our findings and the impact our work has on industry, policy-makers and citizens, as well as future implications. It is an in-depth exploration of how we investigate security and privacy issues and develop methods for solving these problems. 

[Blog 1: Secure AI Assistants: why it matters and what we have learnt so far](https://secure-ai-assistants.github.io/outreach/blog1/)

[Blog 2: Improving transparency in AI Assistants: Researching Alexa privacy and accountability to users](https://secure-ai-assistants.github.io/outreach/blog2/)

### Podcast 
“Always Listening - Can I trust my AI Assistant?” is podcast series produced to address the normal concerns users of voice AI assistant as well as the business and academic communities have. Through example driven explanations and comments from the SAIS team and their industry partners we discuss the technology, privacy issues and future of the industry for a non-scientific audience. We explore essential questions about security and privacy in voice AI assistants, with a particular focus on data from users and the security and privacy implications that these raise. Highlights include explaining the AI Assistant ecosystem, looking at Amazon Alexa as an example, and highlighting security measures in place as well as areas to be aware of. 

[Episode 1: How do AI Assistants work?](/outreach/podcast1)

[Episode 2: My data and controlling how it is used](/outreach/podcast2)

[Episode 3: Misinformation and the future of AI](/outreach/podcast3)

### Exhibition at Science Gallery London
We have been working with Salomé Bazin from Cellule Studio to create Sentient Beings, an evolving soundscape inviting us to question our relationship with AI assistants, how and where we use our voices and the value we place on them.

<div><img src="{{url}}/images/science-gallery.png" class="centred"></div><br />

As a society, the business model of convenience and utility in exchange for our personal data has become habituated in our day-to-day.

Our voices are increasingly becoming a way in which we interact with digital tools - and by extension, the technological corporations who control them. How might this different, more conversational mode of interaction change the ways in which we give away our information? And what additional information might corporations glean from our voices?

The ways in which corporations are able to extract and aggregate information from our voices is opaque. How much vocal data of yourself do think these corporations already have? It may be more than you expect.

Sentient Beings is part of [AI: Who’s Looking After Me?](https://london.sciencegallery.com/ai-season) Opening 21 June at Science Gallery London.

### Other
Our work features in an article by the [Montreal AI Ethics Institute](https://montrealethics.ai/can-you-meaningfully-consent-in-eight-seconds-identifying-ethical-issues-with-verbal-consent-for-voice-assistants/)

<hr />

Be part of the conversation - we would love to hear your comments and feedback.   
Email us on: sais-comms@kcl.ac.uk

Connect with us on [LinkedIn](https://www.linkedin.com/company/sais-project/) and [Twitter](https://twitter.com/SecureAI_SAIS)

